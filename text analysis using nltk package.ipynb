{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\anushka\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: regex in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from nltk) (2020.10.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anushka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter your message: hello my name is anushka and i am an aspiring ML engineer \n",
      "['hello', 'my', 'name', 'is', 'anushka', 'and', 'i', 'am', 'an', 'aspiring', 'ML', 'engineer']\n"
     ]
    }
   ],
   "source": [
    "text = input(\"enter your message: \")\n",
    "tokenized_word = word_tokenize(text)\n",
    "print(tokenized_word)\n",
    "\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "filtered_text = []\n",
    "tokenized_word = word_tokenize(text)\n",
    "for each_word in tokenized_word:\n",
    "    if each_word not in stop_words:\n",
    "        filtered_text.append(each_word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'going', 'to', 'meet', 'MS', 'Dhoni']\n"
     ]
    }
   ],
   "source": [
    "text = 'i am going to meet MS Dhoni'\n",
    "\n",
    "tokenized_word = word_tokenize(text)\n",
    "print(tokenized_word)\n",
    "\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "filtered_text = []\n",
    "tokenized_word = word_tokenize(text)\n",
    "for each_word in tokenized_word:\n",
    "    if each_word not in stop_words:\n",
    "        filtered_text.append(each_word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anushka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'where', 'this', 'in', 'down', 'after', 'm', 'not', 'again', 'their', \"you've\", \"she's\", 'and', 'up', 'y', 'they', 'mustn', 'can', 'on', \"couldn't\", 'when', 'into', 'doing', \"don't\", 'such', \"shan't\", 'only', \"hasn't\", 'all', 'its', 'my', 'does', 'him', 'himself', \"weren't\", 'same', 'had', 'having', 'some', 'off', 'has', 'shouldn', 'itself', 'more', 'few', 'with', 'mightn', \"mustn't\", 'no', \"you'd\", 'themselves', \"shouldn't\", 'needn', 'ourselves', 'whom', 'our', 'shan', 'a', \"hadn't\", 'isn', 'who', 'd', 'until', 'his', 'hers', 'these', 've', 'below', 'be', 'were', 'as', 'them', 'over', 'than', 'how', 'won', 'yourself', 't', 'each', \"that'll\", 'been', 'being', 'weren', 'between', \"mightn't\", 'any', 'me', 'ours', 'the', 'we', 'doesn', 'what', \"it's\", 'why', 'theirs', 'from', 'don', 'll', 'of', \"needn't\", 'for', 'through', 'those', 'too', 'ain', 'you', 'o', 'it', 'did', 'am', 'now', 'hasn', \"you're\", 'i', 're', 'while', 'wouldn', 'ma', \"wasn't\", 'yours', 'your', \"wouldn't\", \"didn't\", 's', 'once', 'but', 'by', 'so', 'further', 'very', 'that', 'hadn', \"you'll\", 'out', 'she', \"haven't\", 'do', \"doesn't\", 'against', 'nor', 'other', 'about', 'because', 'is', 'there', 'or', \"won't\", 'to', 'have', 'which', 'herself', 'at', 'yourselves', 'are', 'just', \"isn't\", 'during', 'her', 'if', \"aren't\", 'was', 'aren', 'before', 'haven', 'will', 'he', 'wasn', 'should', 'didn', 'under', 'myself', 'both', 'own', 'couldn', 'most', 'then', \"should've\", 'above', 'an', 'here'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i am going to meet MS Dhoni']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = 'i am going to meet MS Dhoni'\n",
    "\n",
    "tokenized_word = sent_tokenize(text)\n",
    "print(tokenized_word)\n",
    "\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "filtered_text = []\n",
    "tokenized_word = sent_tokenize(text)\n",
    "for each_word in tokenized_word:\n",
    "    if each_word not in stop_words:\n",
    "        filtered_text.append(each_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Tokens After Removing Punctuations: I'm Anushka Saxena! I'm an engineering student, and i like to code!\n",
      "Stemmed Tokens: ['I', \"'\", 'm', ' ', 'A', 'n', 'u', 's', 'h', 'k', 'a', ' ', 'S', 'a', 'x', 'e', 'n', 'a', '!', ' ', 'I', \"'\", 'm', ' ', 'a', 'n', ' ', 'e', 'n', 'g', 'i', 'n', 'e', 'e', 'r', 'i', 'n', 'g', ' ', 's', 't', 'u', 'd', 'e', 'n', 't', ',', ' ', 'a', 'n', 'd', ' ', 'i', ' ', 'l', 'i', 'k', 'e', ' ', 't', 'o', ' ', 'c', 'o', 'd', 'e', '!']\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "ps = PorterStemmer()\n",
    "\n",
    "filtered_text = \"I'm Anushka Saxena! I'm an engineering student, and i like to code!\"\n",
    "stemmed_words=[]\n",
    "\n",
    "for w in filtered_text:     \n",
    "     stemmed_words.append(ps.stem(w))\n",
    "\n",
    "print(\"Filtered Tokens After Removing Punctuations:\",filtered_text)\n",
    "print(\"Stemmed Tokens:\",stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy--->happi\n",
      "happier--->happier\n",
      "happiest--->happiest\n",
      "happiness--->happi\n",
      "breathing--->breath\n",
      "fairly--->fairli\n",
      "eating--->eat\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pstemmer = PorterStemmer()\n",
    "words = ['happy', 'happier', 'happiest', 'happiness', 'breathing','fairly','eating']\n",
    "for word in words:\n",
    "    print(word + '--->' + pstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Word: fly\n",
      "Stemmed Word: fli\n"
     ]
    }
   ],
   "source": [
    "#Lexicon Normalization#performing stemming and Lemmatization\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "word = \"flying\"\n",
    "\n",
    "print(\"Lemmatized Word:\",lem.lemmatize(word,\"v\"))\n",
    "\n",
    "print(\"Stemmed Word:\",stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Albert', 'Einstein', 'was', 'born', 'in', 'Ulm', ',', 'Germany', 'in', '1879', '.']\n",
      "PoS tags: [('Albert', 'NNP'), ('Einstein', 'NNP'), ('was', 'VBD'), ('born', 'VBN'), ('in', 'IN'), ('Ulm', 'NNP'), (',', ','), ('Germany', 'NNP'), ('in', 'IN'), ('1879', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "sent = \"Albert Einstein was born in Ulm, Germany in 1879.\"\n",
    "\n",
    "tokens=word_tokenize(sent)\n",
    "pos_=pos_tag(tokens)\n",
    "\n",
    "\n",
    "print(\"Tokens:\",tokens)\n",
    "print(\"PoS tags:\",pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPE New York City\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "\n",
    "sent=\"New York City on Tuesday declared a public health emergency and ordered mandatory measles vaccinations amid an outbreak, becoming the latest national flash point over refusals to inoculate against dangerous diseases.\"\n",
    "\n",
    "for chunk in ne_chunk(nltk.pos_tag(word_tokenize(sent))):\n",
    "        if hasattr(chunk, 'label'):\n",
    "            print(chunk.label(), ' '.join(c[0] for c in chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS USING TEXTBLOB LIBRARY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\anushka\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1; python_version >= \"3\" in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: regex in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (2020.10.15)\n",
      "Requirement already satisfied: click in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (4.50.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (0.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type your sentense: hello my name is anuhska, i am a good girl\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "text = input(\"type your sentense: \")\n",
    "edu=TextBlob(text)\n",
    "\n",
    "x = edu.sentiment.polarity\n",
    "# polarity is negetive when x<0, polarity is neutral when x=0, polarity is positive when x>0 and x<=1\n",
    "\n",
    "if x<0:\n",
    "    print(\"negetive\")\n",
    "elif x==0:\n",
    "    print(\"neutral\")\n",
    "elif x>0 and x<1:\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newspaper\n",
      "  Using cached newspaper-0.1.0.7.tar.gz (176 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\Anushka\\anaconda3\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Anushka\\\\AppData\\\\Local\\\\Temp\\\\pip-install-mygc2h9m\\\\newspaper\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Anushka\\\\AppData\\\\Local\\\\Temp\\\\pip-install-mygc2h9m\\\\newspaper\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\Anushka\\AppData\\Local\\Temp\\pip-pip-egg-info-o0x3flpf'\n",
      "         cwd: C:\\Users\\Anushka\\AppData\\Local\\Temp\\pip-install-mygc2h9m\\newspaper\\\n",
      "    Complete output (1 lines):\n",
      "    WARNING! You are attempting to install newspaper's python2 repository on python3. PLEASE RUN `$ pip3 install newspaper3k` for python3 or `$ pip install newspaper` for python2\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "pip install newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newspaper3k in c:\\users\\anushka\\anaconda3\\lib\\site-packages (0.2.8)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (4.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (2.8.1)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: nltk>=3.2.1 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (3.5)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (0.0.4)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (0.3)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (0.35.1)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (6.0.10)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (8.0.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (2.24.0)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (3.3.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (4.9.3)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: PyYAML>=3.11 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from newspaper3k) (5.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->newspaper3k) (1.15.0)\n",
      "Requirement already satisfied: click in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (0.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (4.50.2)\n",
      "Requirement already satisfied: regex in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (2020.10.15)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\anushka\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.0.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://timesofindia.indiatimes.com/city/rajkot/gujarat-boy-robs-disability-of-its-power-to-kill-his-dream/articleshow/91822746.cms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAJKOT: To bell the CAT is one thing, but to bell the CAT blindfolded in a darkroom takes the level of success to a much higher plane — something that visually impaired Karan Kanakhara, who not only cracked the test, but also secured a seat in IIM Calcutta, is savouring at the moment.The inspiration for the 20- year-old not to give in to desperation and beat the odds started quite early in Class 8 when retinitis pigmentosa (RP) — an inherited disease — started to rob him of his eyesight gradually.But the native of Jamnagar hung on to hope and his firm belief in the adage: “Winners don’t do different things, they do things differently!”According to Karan, this quote sprung him back every time life pushed him towards disappointment.Currently with just 20 per cent vision, as he prepares to face the challenges of a management life, Karan is grateful for the unstinting support of his parents, Jitendra and Puja Kanakhara, and his elder sister Shraddha besides his teacher, Illaba Sodha, who helped him dispel any doubt he had about achieving his goals.“With their support I changed my learning style. I started listening more than reading the study material and tried to memorize it. While I prepared audio study materials, I should mention about my mother, who especially prepared a great deal of audio study material for me,” Karan told TOI.Karan appeared for his SSC exam as a normal student , but his difficulty in seeing increased thereafter. He then appeared for the HSC exam under Person with Disability (PWD) category, in which he was allowed some more time to write the paper and also allowed to carry a separate light in the examination hall. Karan scored 99 percentile in both the board exams.Father Jitendra Kanakhara had an ice cream parlour in Jamnagar. But recognizing his son’s talent, he sold off the property there and the family shifted to Ahmedabad to support Karan in his further studies.From the first year of his graduation, Karan Kanakhara started preparing for CAT as he always nurtured a dream to study at an IIM. However, during the pandemic, Karan not only found it difficult to find a writer but he also had to sit for online exams. He accepted the challenge and kept the mobile screen close to his eyes while appearing in the exams. Karan received huge support in the college from his principal Sanjay Vakil, prof Chetan Mewada and many others.“I took the CAT last year. On Wednesday, I got an offer letter from IIM Calcutta for MBA admission. I will have to join from next month. My dream has finally come true. I want to specialize in marketing,” said Karan.(With inputs from Kiritsinh Zala)\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.152\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "sentiment=blob.sentiment.polarity #range -1 to 1; -1=negetive, 1=positive\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=article.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I started listening more than reading the study material and tried to memorize it.\n",
      "Karan scored 99 percentile in both the board exams.Father Jitendra Kanakhara had an ice cream parlour in Jamnagar.\n",
      "However, during the pandemic, Karan not only found it difficult to find a writer but he also had to sit for online exams.\n",
      "He accepted the challenge and kept the mobile screen close to his eyes while appearing in the exams.\n",
      "Karan received huge support in the college from his principal Sanjay Vakil, prof Chetan Mewada and many others.“I took the CAT last year.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.152\n"
     ]
    }
   ],
   "source": [
    "blob=TextBlob(text)\n",
    "sentiment=blob.sentiment.polarity\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
